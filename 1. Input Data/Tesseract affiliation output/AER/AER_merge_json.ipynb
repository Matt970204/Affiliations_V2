{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge AER json files together\n",
    "# Missing 1943 won't load\n",
    "# 1969 missing\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('AER_aff_output_1940_N.json') as f0:               # open the file\n",
    "    data0 = json.load(f0)\n",
    "\n",
    "with open('AER_aff_output_1941_N.json') as f1:               # open the file\n",
    "    data1 = json.load(f1)\n",
    "\n",
    "with open('AER_aff_output_1942_N.json') as f2:                # open the file       \n",
    "    data2 = json.load(f2)\n",
    "\n",
    "with open('AER_aff_output_1943_N.json') as f3:                # open the file       \n",
    "    data3 = json.load(f3)\n",
    "\n",
    "with open('AER_aff_output_1944_N.json') as f4:                # open the file       \n",
    "    data4 = json.load(f4)\n",
    "\n",
    "with open('AER_aff_output_1945_N.json') as f5:                # open the file       \n",
    "    data5 = json.load(f5)\n",
    "\n",
    "with open('AER_aff_output_1946_N.json') as f6:                # open the file       \n",
    "    data6 = json.load(f6)\n",
    "\n",
    "with open('AER_aff_output_1947_N.json') as f7:                # open the file       \n",
    "    data7 = json.load(f7)\n",
    "\n",
    "with open('AER_aff_output_1948_N.json') as f8:                # open the file       \n",
    "    data8 = json.load(f8)\n",
    "\n",
    "with open('AER_aff_output_1949_N.json') as f9:                # open the file       \n",
    "    data9 = json.load(f9)\n",
    "\n",
    "with open('AER_aff_output_1950_N.json') as f10:               # open the file\n",
    "    data10 = json.load(f10)\n",
    "\n",
    "with open('AER_aff_output_1951_N.json') as f11:               # open the file\n",
    "    data11 = json.load(f11)\n",
    "\n",
    "with open('AER_aff_output_1952_N.json') as f12:                # open the file       \n",
    "    data12 = json.load(f12)\n",
    "\n",
    "with open('AER_aff_output_1953_N.json') as f13:                # open the file       \n",
    "    data13 = json.load(f13)\n",
    "\n",
    "with open('AER_aff_output_1954_N.json') as f14:                # open the file       \n",
    "    data14 = json.load(f14)\n",
    "\n",
    "with open('AER_aff_output_1955_N.json') as f15:                # open the file       \n",
    "    data15 = json.load(f15)\n",
    "\n",
    "with open('AER_aff_output_1956_N.json') as f16:                # open the file       \n",
    "    data16 = json.load(f16)\n",
    "\n",
    "with open('AER_aff_output_1957_N.json') as f17:                # open the file       \n",
    "    data17 = json.load(f17)\n",
    "\n",
    "with open('AER_aff_output_1958_N.json') as f18:                # open the file       \n",
    "    data18 = json.load(f18)\n",
    "\n",
    "with open('AER_aff_output_1959_N.json') as f19:                # open the file       \n",
    "    data19 = json.load(f19)\n",
    "\n",
    "with open('AER_aff_output_1960_N.json') as f20:               # open the file\n",
    "    data20 = json.load(f20)\n",
    "\n",
    "with open('AER_aff_output_1961_N.json') as f21:               # open the file\n",
    "    data21 = json.load(f21)\n",
    "\n",
    "with open('AER_aff_output_1962_N.json') as f22:                # open the file       \n",
    "    data22 = json.load(f22)\n",
    "\n",
    "with open('AER_aff_output_1963_N.json') as f23:                # open the file       \n",
    "    data23 = json.load(f23)\n",
    "\n",
    "with open('AER_aff_output_1964_N.json') as f24:                # open the file       \n",
    "    data24 = json.load(f24)\n",
    "\n",
    "with open('AER_aff_output_1965_N.json') as f25:                # open the file       \n",
    "    data25 = json.load(f25)\n",
    "\n",
    "with open('AER_aff_output_1966_N.json') as f26:                # open the file       \n",
    "    data26 = json.load(f26)\n",
    "\n",
    "with open('AER_aff_output_1967_N.json') as f27:                # open the file       \n",
    "    data27 = json.load(f27)\n",
    "\n",
    "with open('AER_aff_output_1968_N.json') as f28:                # open the file       \n",
    "    data28 = json.load(f28)\n",
    "\n",
    "#with open('AER_aff_output_1969_N.json') as f29:                # no 1969    \n",
    "#   data29 = json.load(f29)\n",
    "\n",
    "with open('AER_aff_output_1970_1971_N.json') as f29:                # open the file       \n",
    "    data29 = json.load(f29)\n",
    "    \n",
    "with open('AER_aff_output_1971_1980.json') as f30:                # open the file       \n",
    "    data30 = json.load(f30)\n",
    "\n",
    "with open('AER_aff_output_1981_1990.json') as f31:                # open the file       \n",
    "    data31 = json.load(f31)\n",
    "\n",
    "with open('AER_aff_output_1991_2000.json') as f32:                # open the file       \n",
    "    data32 = json.load(f32)\n",
    "\n",
    "with open('AER_aff_output_2001_2010.json') as f33:                # open the file       \n",
    "    data33 = json.load(f33)\n",
    "\n",
    "# Creating DataFrames\n",
    "df0 = pd.DataFrame([data0]) \n",
    "df1 = pd.DataFrame([data1])                      \n",
    "df2 = pd.DataFrame([data2])  \n",
    "#df3 = pd.DataFrame([data3])     errors\n",
    "df4 = pd.DataFrame([data4])                      \n",
    "df5 = pd.DataFrame([data5])  \n",
    "df6 = pd.DataFrame([data6])   \n",
    "df7 = pd.DataFrame([data7])                      \n",
    "df8 = pd.DataFrame([data8])  \n",
    "df9 = pd.DataFrame([data9])      \n",
    "\n",
    "df10 = pd.DataFrame([data10]) \n",
    "df11 = pd.DataFrame([data11])                      \n",
    "df12 = pd.DataFrame([data12])  \n",
    "df13 = pd.DataFrame([data13])    \n",
    "df14 = pd.DataFrame([data14])                      \n",
    "df15 = pd.DataFrame([data15])  \n",
    "df16 = pd.DataFrame([data16])   \n",
    "df17 = pd.DataFrame([data17])                      \n",
    "df18 = pd.DataFrame([data18])  \n",
    "df19 = pd.DataFrame([data19]) \n",
    "\n",
    "df20 = pd.DataFrame([data20]) \n",
    "df21 = pd.DataFrame([data21])                      \n",
    "df22 = pd.DataFrame([data22])  \n",
    "df23 = pd.DataFrame([data23])    \n",
    "df24 = pd.DataFrame([data24])                      \n",
    "df25 = pd.DataFrame([data25])  \n",
    "df26 = pd.DataFrame([data26])   \n",
    "df27 = pd.DataFrame([data27])                      \n",
    "df28 = pd.DataFrame([data28])  \n",
    "#df29 = pd.DataFrame([data29]) \n",
    "\n",
    "df30 = pd.DataFrame([data30]) \n",
    "df31 = pd.DataFrame([data31]) \n",
    "df32 = pd.DataFrame([data32]) \n",
    "df33 = pd.DataFrame([data33]) \n",
    "\n",
    "MergeJson = pd.concat([df0, df1, df2, df4, df5, df6, df7, df8, df9 , df10, df11, df12, df13, df14, df15, df16, df17, df18, df19, df20, df21, df22, df23, df24, df25, df26, df27, df28, df30, df31, df32, df33], axis=1)\n",
    "#MergeJson = pd.concat([df0, df1, df2, df3, df4, df5, df6, df7, df8, df9], axis=1)         # Concat DataFrames\n",
    "\n",
    "        # Writing Json\n",
    "MergeJson.to_json(\"AER_aff_output_1940_2010_merged test.json\")  \n",
    "\n",
    "#data = AER_aff_output_1940_2010_merged test.json\n",
    "#data.update(data.pop(\"0\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>41038751</th>\n",
       "      <th>41038752</th>\n",
       "      <th>41038753</th>\n",
       "      <th>41038754</th>\n",
       "      <th>41038755</th>\n",
       "      <th>41038756</th>\n",
       "      <th>41038757</th>\n",
       "      <th>41038758</th>\n",
       "      <th>41038759</th>\n",
       "      <th>41038760</th>\n",
       "      <th>...</th>\n",
       "      <th>2677907</th>\n",
       "      <th>2677908</th>\n",
       "      <th>2677909</th>\n",
       "      <th>2677910</th>\n",
       "      <th>2677911</th>\n",
       "      <th>2677912</th>\n",
       "      <th>2677913</th>\n",
       "      <th>2677914</th>\n",
       "      <th>2677915</th>\n",
       "      <th>2677916</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'affiliations': {'found': '* Department of Ec...</td>\n",
       "      <td>{'affiliations': {'found': '* Mian: University...</td>\n",
       "      <td>{'affiliations': {'found': '* Muendler: Depart...</td>\n",
       "      <td>{'affiliations': {'found': '*Comin: Harvard Bu...</td>\n",
       "      <td>{'affiliations': {'found': '*Algan: Sciences P...</td>\n",
       "      <td>{'affiliations': {'found': '* Department of Ec...</td>\n",
       "      <td>{'affiliations': {'found': '* Avery: Kennedy S...</td>\n",
       "      <td>{'affiliations': {'found': '\"Anderson: Departm...</td>\n",
       "      <td>{'affiliations': {'found': '* Grosskopf: Depar...</td>\n",
       "      <td>{'affiliations': {'found': '* Dal Bó: Departme...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'affiliations': {'found': '* Jensen: Departme...</td>\n",
       "      <td>{'affiliations': {'found': '* Department of Ec...</td>\n",
       "      <td>{'affiliations': {'found': '* Department of Ec...</td>\n",
       "      <td>{'affiliations': {'found': '* Steckel: Departm...</td>\n",
       "      <td>{'affiliations': {'found': '* Department of Ec...</td>\n",
       "      <td>{'affiliations': {'found': '* Putnam Investmen...</td>\n",
       "      <td>{'affiliations': {'found': '* School of Busine...</td>\n",
       "      <td>{'affiliations': {'found': '* Di Tella: Harvar...</td>\n",
       "      <td>{'affiliations': {'found': '* Department of Ec...</td>\n",
       "      <td>{'affiliations': {'found': '* Department of Ec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1906 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            41038751  \\\n",
       "0  {'affiliations': {'found': '* Department of Ec...   \n",
       "\n",
       "                                            41038752  \\\n",
       "0  {'affiliations': {'found': '* Mian: University...   \n",
       "\n",
       "                                            41038753  \\\n",
       "0  {'affiliations': {'found': '* Muendler: Depart...   \n",
       "\n",
       "                                            41038754  \\\n",
       "0  {'affiliations': {'found': '*Comin: Harvard Bu...   \n",
       "\n",
       "                                            41038755  \\\n",
       "0  {'affiliations': {'found': '*Algan: Sciences P...   \n",
       "\n",
       "                                            41038756  \\\n",
       "0  {'affiliations': {'found': '* Department of Ec...   \n",
       "\n",
       "                                            41038757  \\\n",
       "0  {'affiliations': {'found': '* Avery: Kennedy S...   \n",
       "\n",
       "                                            41038758  \\\n",
       "0  {'affiliations': {'found': '\"Anderson: Departm...   \n",
       "\n",
       "                                            41038759  \\\n",
       "0  {'affiliations': {'found': '* Grosskopf: Depar...   \n",
       "\n",
       "                                            41038760  ...  \\\n",
       "0  {'affiliations': {'found': '* Dal Bó: Departme...  ...   \n",
       "\n",
       "                                             2677907  \\\n",
       "0  {'affiliations': {'found': '* Jensen: Departme...   \n",
       "\n",
       "                                             2677908  \\\n",
       "0  {'affiliations': {'found': '* Department of Ec...   \n",
       "\n",
       "                                             2677909  \\\n",
       "0  {'affiliations': {'found': '* Department of Ec...   \n",
       "\n",
       "                                             2677910  \\\n",
       "0  {'affiliations': {'found': '* Steckel: Departm...   \n",
       "\n",
       "                                             2677911  \\\n",
       "0  {'affiliations': {'found': '* Department of Ec...   \n",
       "\n",
       "                                             2677912  \\\n",
       "0  {'affiliations': {'found': '* Putnam Investmen...   \n",
       "\n",
       "                                             2677913  \\\n",
       "0  {'affiliations': {'found': '* School of Busine...   \n",
       "\n",
       "                                             2677914  \\\n",
       "0  {'affiliations': {'found': '* Di Tella: Harvar...   \n",
       "\n",
       "                                             2677915  \\\n",
       "0  {'affiliations': {'found': '* Department of Ec...   \n",
       "\n",
       "                                             2677916  \n",
       "0  {'affiliations': {'found': '* Department of Ec...  \n",
       "\n",
       "[1 rows x 1906 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df33.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
